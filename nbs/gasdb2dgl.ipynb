{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import numpy as np \n",
    "import dgl\n",
    "from gaspy_utils import make_atoms_from_doc\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "import json\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.analysis.structure_analyzer import VoronoiConnectivity\n",
    "from ase.constraints import FixAtoms\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import copy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gaspy_docs/docs.pkl','rb') as infile:\n",
    "    gasdb = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsorbates = [doc['adsorbate'] for doc in gasdb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsorbates = list(set(adsorbates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5 unique adsorbates\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(adsorbates)} unique adsorbates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dgl import backend as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomInitializer(object):\n",
    "    \"\"\"\n",
    "    Base class for intializing the vector representation for atoms.\n",
    "\n",
    "    !!! Use one AtomInitializer per dataset !!!\n",
    "    \"\"\"\n",
    "    def __init__(self, atom_types):\n",
    "        self.atom_types = set(atom_types)\n",
    "        self._embedding = {}\n",
    "\n",
    "    def get_atom_fea(self, atom_type):\n",
    "        assert atom_type in self.atom_types\n",
    "        return self._embedding[atom_type]\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self._embedding = state_dict\n",
    "        self.atom_types = set(self._embedding.keys())\n",
    "        self._decodedict = {idx: atom_type for atom_type, idx in\n",
    "                            self._embedding.items()}\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self._embedding\n",
    "\n",
    "    def decode(self, idx):\n",
    "        if not hasattr(self, '_decodedict'):\n",
    "            self._decodedict = {idx: atom_type for atom_type, idx in\n",
    "                                self._embedding.items()}\n",
    "        return self._decodedict[idx]\n",
    "\n",
    "\n",
    "class AtomCustomJSONInitializer(AtomInitializer):\n",
    "    \"\"\"\n",
    "    Initialize atom feature vectors using a JSON file, which is a python\n",
    "    dictionary mapping from element number to a list representing the\n",
    "    feature vector of the element.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    elem_embedding_file: str\n",
    "        The path to the .json file\n",
    "    \"\"\"\n",
    "    def __init__(self, elem_embedding_file):\n",
    "        with open(elem_embedding_file) as f:\n",
    "            elem_embedding = json.load(f)\n",
    "        elem_embedding = {int(key): value for key, value\n",
    "                          in elem_embedding.items()}\n",
    "        atom_types = set(elem_embedding.keys())\n",
    "        super(AtomCustomJSONInitializer, self).__init__(atom_types)\n",
    "        for key, value in elem_embedding.items():\n",
    "            self._embedding[key] = np.array(value, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_adsorbate_feature(atoms, VC, max_dist = 6):    \n",
    "    # This function looks at an atoms object and attempts to find\n",
    "    # the minimum distance from each atom to one of the adsorbate \n",
    "    # atoms (marked with tag==1)\n",
    "    conn = copy.deepcopy(VC.connectivity_array)\n",
    "    conn = np.max(conn,2)\n",
    "\n",
    "    for i in range(len(conn)):\n",
    "        conn[i]=conn[i]/np.max(conn[i])\n",
    "\n",
    "    #get a binary connectivity matrix\n",
    "    conn=(conn>0.3)*1\n",
    "    \n",
    "    #Everything is connected to itself, so add a matrix with zero on the diagonal \n",
    "    # and a large number on the off-diagonal\n",
    "    ident_connection = np.eye(len(conn))\n",
    "    ident_connection[ident_connection==0]=max_dist+1\n",
    "    ident_connection[ident_connection==1]=0\n",
    "\n",
    "    #For each distance, add an array of atoms that can be connected at that distance\n",
    "    arrays = [ident_connection]\n",
    "    for i in range(1,max_dist):\n",
    "        arrays.append((np.linalg.matrix_power(conn,i)>=1)*i+(np.linalg.matrix_power(conn,i)==0)*(max_dist+1))\n",
    "\n",
    "    #Find the minimum distance from each atom to every other atom (over possible distances)\n",
    "    arrays=np.min(arrays,0)\n",
    "\n",
    "    # Find the minimum distance from one of the adsorbate atoms to the other atoms\n",
    "    min_distance_to_adsorbate = np.min(arrays[atoms.get_tags()==1],0).reshape((-1,1))\n",
    "    \n",
    "    #Make sure all of the one hot distance vectors are encoded to the same length. \n",
    "    # Encode, return\n",
    "    min_distance_to_adsorbate[min_distance_to_adsorbate>=max_dist]=max_dist-1\n",
    "    OHE = OneHotEncoder(categories=[range(max_dist)]).fit(min_distance_to_adsorbate)\n",
    "    return OHE.transform(min_distance_to_adsorbate).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crystal_atom_featurizer(atoms):\n",
    "    \"\"\"\n",
    "    takes ASE.atoms object\n",
    "    return num_atoms and\n",
    "    atom featurizer dict with tags and fixed locations using ASE.constraints\n",
    "    \"\"\"\n",
    "    crystal = AseAtomsAdaptor.get_structure(atoms)\n",
    "    VC = VoronoiConnectivity(crystal)\n",
    "    atom_feats_dict = defaultdict(list)\n",
    "    num_atoms = atoms.get_global_number_of_atoms()\n",
    "    atomic_numbers = atoms.get_atomic_numbers()\n",
    "    tags = atoms.get_tags()\n",
    "    fix_loc, = np.where([type(constraint)==FixAtoms for constraint in atoms.constraints])\n",
    "    fix_atoms_indices = set(atoms.constraints[fix_loc[0]].get_indices())\n",
    "    fixed_atoms = [i in fix_atoms_indices for i in range(len(atoms))]\n",
    "    for i in range(num_atoms):\n",
    "        atom_feats = list(ari.get_atom_fea(atomic_numbers[i])) #get init feats from json and convert to list\n",
    "        atom_feats.append(tags[i])\n",
    "        atom_feats.append(fixed_atoms[i])\n",
    "        atom_feats_dict['n_feat'].append(F.tensor(np.array(atom_feats).astype(np.float32))) #make it into tensor float32\n",
    "    atom_feats_dict['n_feat'] = F.stack(atom_feats_dict['n_feat'],dim=0)#finally all together \n",
    "    distance_to_adsorbate_feats = distance_to_adsorbate_feature(atoms,VC)\n",
    "    atom_feats_dict['n_feat'] = F.cat((atom_feats_dict['n_feat'],F.tensor(distance_to_adsorbate_feats.astype(np.float32))),dim=1)# np.hstack\n",
    "    return num_atoms, atom_feats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari = AtomCustomJSONInitializer('../atom_init.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDistance(object):\n",
    "    \"\"\"\n",
    "    Expands the distance by Gaussian basis.\n",
    "\n",
    "    Unit: angstrom\n",
    "    \"\"\"\n",
    "    def __init__(self, dmin, dmax, step, var=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        dmin: float\n",
    "          Minimum interatomic distance\n",
    "        dmax: float\n",
    "          Maximum interatomic distance\n",
    "        step: float\n",
    "          Step size for the Gaussian filter\n",
    "        \"\"\"\n",
    "        assert dmin < dmax\n",
    "        assert dmax - dmin > step\n",
    "        self.filter = np.arange(dmin, dmax+step, step)\n",
    "        if var is None:\n",
    "            var = step\n",
    "        self.var = var\n",
    "\n",
    "    def expand(self, distances):\n",
    "        \"\"\"\n",
    "        Apply Gaussian distance filter to a numpy distance array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        distance: np.array shape n-d array\n",
    "          A distance matrix of any shape\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        expanded_distance: shape (n+1)-d array\n",
    "          Expanded distance matrix with the last dimension of length\n",
    "          len(self.filter)\n",
    "        \"\"\"\n",
    "        return np.exp(-(distances[..., np.newaxis] - self.filter)**2 /\n",
    "                      self.var**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = GaussianDistance(0,8,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crystal_bond_featurizer(atoms,atoms_init_config, train_geometry,gdf, max_neighbors):\n",
    "    \"\"\"\n",
    "    takes ASE.atoms object of final and initial_config and returns bond \n",
    "    features upto max_neighbors using gaussian distance object based on train_geometry\n",
    "    returns bond_feats_dict with e_feat and gdf_feat \n",
    "    along with src_list, dst_list and total_bonds\n",
    "    \"\"\"\n",
    "    crystal = AseAtomsAdaptor.get_structure(atoms)\n",
    "    VC = VoronoiConnectivity(crystal)\n",
    "    conn = copy.deepcopy(VC.connectivity_array)\n",
    "    atoms_initial_config = copy.deepcopy(atoms_init_config)\n",
    "    crystal_initial_config = AseAtomsAdaptor.get_structure(atoms_initial_config)\n",
    "    VC_initial_config = VoronoiConnectivity(crystal_initial_config)\n",
    "    conn_initial_config = copy.deepcopy(VC_initial_config.connectivity_array)\n",
    "    all_nbrs = []          \n",
    "    # Loop over central atom\n",
    "    for ii in range(0, conn.shape[0]):\n",
    "        curnbr = []\n",
    "\n",
    "        #Loop over neighbor atoms\n",
    "        for jj in range(0, conn.shape[1]):\n",
    "\n",
    "            #Loop over each possible PBC image for the chosen image\n",
    "            for kk in range(0,conn.shape[2]):\n",
    "                # Only add as a neighbor if the atom is not the currently selected center one and there is connectivity\n",
    "                # to that image\n",
    "                if jj is not kk and conn[ii][jj][kk] != 0:\n",
    "\n",
    "                    #Add the neighbor strength depending on train_geometry base\n",
    "                    if train_geometry =='initial':\n",
    "                        curnbr.append([ii, conn_initial_config[ii][jj][kk]/np.max(conn_initial_config[ii]), jj])\n",
    "                    elif train_geometry =='final':\n",
    "                        curnbr.append([ii, conn[ii][jj][kk]/np.max(conn[ii]), jj])\n",
    "                    elif train_geometry == 'final-adsorbate':\n",
    "                        #In order for this to work, each adsorbate atom should be set to tag==1 in the atoms object\n",
    "                        if (atoms.get_tags()[ii]==1 or atoms.get_tags()[jj]==1):\n",
    "                            if conn[ii][jj][kk]/np.max(conn[ii])>0.3:\n",
    "                                curnbr.append([ii, 1.0, jj])\n",
    "                            else:\n",
    "                                curnbr.append([ii, 0.0, jj])\n",
    "                        else:\n",
    "                            curnbr.append([ii, conn_initial_config[ii][jj][kk]/np.max(conn_initial_config[ii]), jj])\n",
    "\n",
    "                    else:\n",
    "                        curnbr.append([ii, conn[ii][jj][kk]/np.max(conn[ii]), jj])\n",
    "\n",
    "                else:\n",
    "                    curnbr.append([ii, 0.0, jj])\n",
    "        all_nbrs.append(np.array(curnbr))\n",
    "    all_nbrs = np.array(all_nbrs)\n",
    "    total_bonds = all_nbrs.shape[1]\n",
    "    all_nbrs = [sorted(nbrs, key=lambda x: x[1],reverse=True) for nbrs in all_nbrs]\n",
    "    nbr_fea_idx = np.array([list(map(lambda x: x[2],\n",
    "                            nbr[:max_neighbors])) for nbr in all_nbrs])\n",
    "    nbr_fea = np.array([list(map(lambda x: x[1], nbr[:max_neighbors]))\n",
    "                    for nbr in all_nbrs])\n",
    "    gdf_nbr = gdf.expand(nbr_fea)\n",
    "    bond_feats_dict = defaultdict(list)\n",
    "    src_list = []\n",
    "    dst_list = []\n",
    "    for i in range(len(nbr_fea_idx)):\n",
    "        for j in nbr_fea_idx[i]:\n",
    "            if not i == j:\n",
    "                src_list.extend([int(i),int(j)])\n",
    "                bond_feats_dict['e_feat'].append(np.array(nbr_fea[int(i)][list(nbr_fea_idx[i]).index(j)]))\n",
    "                bond_feats_dict['gdf_feat'].append(np.array(gdf_nbr[int(i)][list(nbr_fea_idx[i]).index(j)]))\n",
    "                dst_list.extend([int(j),int(i)])\n",
    "                bond_feats_dict['e_feat'].append(np.zeros(1))\n",
    "                bond_feats_dict['gdf_feat'].append(np.zeros(gdf_nbr.shape[-1]))\n",
    "    bond_feats_dict['e_feat'] = F.tensor(np.array(bond_feats_dict['e_feat']).astype(np.float32))\n",
    "    bond_feats_dict['gdf_feat'] = F.tensor(np.array(bond_feats_dict['gdf_feat']).astype(np.float32))\n",
    "    return src_list, dst_list, total_bonds, bond_feats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atoms, atoms_feats_dict = crystal_atom_featurizer(make_atoms_from_doc(gasdb[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_list, dst_list, total_bonds, bond_feats_dict = crystal_bond_featurizer(make_atoms_from_doc(gasdb[0]),\n",
    "                                                      make_atoms_from_doc(gasdb[0]['initial_configuration']),\n",
    "                                                      'final-adsorbate',\n",
    "                                                      gdf,\n",
    "                                                      12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dgl_graph(doc, atom_featurizer, bond_featurizer,gdf,train_geometry, max_neighbors):\n",
    "    g = dgl.DGLGraph()\n",
    "    atoms = make_atoms_from_doc(doc)\n",
    "    init_atoms = make_atoms_from_doc(doc['initial_configuration'])\n",
    "    num_atoms, atoms_feats_dict = atom_featurizer(atoms)\n",
    "    src_list, dst_list, total_bonds, bond_feats_dict = bond_featurizer(atoms,\n",
    "                                                      init_atoms,\n",
    "                                                      train_geometry,\n",
    "                                                      gdf,\n",
    "                                                      max_neighbors)\n",
    "    g.add_nodes(num_atoms)\n",
    "    g.add_edges(src_list,dst_list)\n",
    "    g.ndata.update(atoms_feats_dict)\n",
    "    g.edata.update(bond_feats_dict)\n",
    "    g.adsorbate = doc['adsorbate']\n",
    "    g.mpid = doc['mpid']\n",
    "    g.miller = doc['miller']\n",
    "    g.comp = list(set(atoms.get_chemical_symbols()))\n",
    "    g.target = doc['energy']\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets = adsorption energies\n",
    "targets = np.array([doc['energy'] for doc in gasdb]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import multiprocessing as mp \n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_final_adsorbate_graphs = partial(make_dgl_graph,atom_featurizer=crystal_atom_featurizer, \n",
    "                             bond_featurizer=crystal_bond_featurizer,\n",
    "                             gdf=gdf,\n",
    "                             train_geometry='final-adsorbate', \n",
    "                             max_neighbors=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graphs = [make_final_adsorbate_graphs(doc) for doc in gasdb[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b77b5a309ae4059b5ef54c9af416f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r1 = r = process_map(make_final_adsorbate_graphs, gasdb[:1000],max_workers=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(processes=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = pool.map(make_final_adsorbate_graphs, gasdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphs = []\n",
    "with mp.Pool(24) as pool:\n",
    "    iterator = pool.map(make_final_adsorbate_graphs,gasdb)\n",
    "    _graphs = list(tqdm(iterator, total=len(gasdb),\n",
    "                      desc='Transforming docs in a chunk'))\n",
    "    graphs.extend(_graphs)\n",
    "    iterator.start()\n",
    "    iterator.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of converted graphs  {len(graphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/scratch/westgroup/mpnn/gasdb_dgl_graphs/init_gasdb_dgl_graphs.pkl','wb') as outfile:\n",
    "    pickle.dump(r1,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch.utils import Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CG(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                in_feats,\n",
    "                h_feats,\n",
    "                out_feats,):\n",
    "        super(CG, self).__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.h_feats = h_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.lin = torch.nn.Linear(2*in_feats+41,h_feats)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.softplus = torch.nn.LeakyReLU()\n",
    "\n",
    "    def get_msg(self, edges):\n",
    "        z = torch.cat([edges.src['n_feat'], edges.dst['n_feat'],edges.data['gdf_feat']], -1)\n",
    "        z = self.lin(z)\n",
    "        sig_z = self.sigmoid(z)\n",
    "        softplus_z = self.softplus(z)\n",
    "        return {'z':sig_z*softplus_z}\n",
    "    def forward(self, graph):\n",
    "        #graph.apply_edges(self.get_msg)\n",
    "        graph.update_all(message_func=self.get_msg,\n",
    "                     reduce_func=fn.sum('z', 'm'))\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg =CG(100,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = cg.forward(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.ndata['m'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
